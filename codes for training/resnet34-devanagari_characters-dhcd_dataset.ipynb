{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10881742,"sourceType":"datasetVersion","datasetId":6761558}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-01T14:58:05.980877Z","iopub.execute_input":"2025-03-01T14:58:05.981190Z","iopub.status.idle":"2025-03-01T15:01:01.334404Z","shell.execute_reply.started":"2025-03-01T14:58:05.981168Z","shell.execute_reply":"2025-03-01T15:01:01.333259Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install wandb\nfrom kaggle_secrets import UserSecretsClient\nimport wandb\nuser_secrets = UserSecretsClient()\n\nmy_secret = user_secrets.get_secret(\"wandb_api_key\") \n\nwandb.login(key=my_secret)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T02:24:32.517824Z","iopub.execute_input":"2025-03-04T02:24:32.518162Z","iopub.status.idle":"2025-03-04T02:24:36.085127Z","shell.execute_reply.started":"2025-03-04T02:24:32.518138Z","shell.execute_reply":"2025-03-04T02:24:36.083912Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CFG = {\n    'model_name' : 'RESNET-34',\n    'BATCH_SIZE' : 32,\n    'LEARNING_RATE' : 0.001,\n    'MOMENTUM' : 0.9,\n    'STEP_SIZE' : 7,\n    'GAMMA' : 0.1,\n    'EPOCHS' : 15,\n    'TRAIN_DIR' : '/kaggle/input/prasansa-data/DevanagariHandwrittenCharacterDataset/Train',\n    'TEST_DIR' : '/kaggle/input/prasansa-data/DevanagariHandwrittenCharacterDataset/Test'\n}\n\n# Initialise run\nrun = wandb.init(project = 'devnagari_character_recog',\n                 config = CFG,\n                 save_code = True,\n                 name='RESNET-34_train'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T15:41:04.430331Z","iopub.execute_input":"2025-03-03T15:41:04.430682Z","iopub.status.idle":"2025-03-03T15:41:19.318323Z","shell.execute_reply.started":"2025-03-03T15:41:04.430659Z","shell.execute_reply":"2025-03-03T15:41:19.317667Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport time\nimport copy\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport pandas as pd\nfrom torch.utils.data import DataLoader, random_split, Dataset\n\n# Set device\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T14:00:51.313290Z","iopub.execute_input":"2025-03-02T14:00:51.313610Z","iopub.status.idle":"2025-03-02T14:01:03.405024Z","shell.execute_reply.started":"2025-03-02T14:00:51.313587Z","shell.execute_reply":"2025-03-02T14:01:03.404381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hyperparameters\nBATCH_SIZE = CFG['BATCH_SIZE']\nLEARNING_RATE = CFG['LEARNING_RATE']\nMOMENTUM = CFG['MOMENTUM']\nSTEP_SIZE = CFG['STEP_SIZE']\nGAMMA = CFG['GAMMA']\nEPOCHS = CFG['EPOCHS']\n\nTRAIN_DIR = CFG['TRAIN_DIR']\nTEST_DIR = CFG['TEST_DIR']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T14:01:03.406039Z","iopub.execute_input":"2025-03-02T14:01:03.406339Z","iopub.status.idle":"2025-03-02T14:01:11.612721Z","shell.execute_reply.started":"2025-03-02T14:01:03.406311Z","shell.execute_reply":"2025-03-02T14:01:11.612088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Custom Dataset wrapper for applying transforms\nclass TransformedSubset(Dataset):\n    def __init__(self, subset, transform=None):\n        self.subset = subset\n        self.transform = transform\n\n    def __getitem__(self, index):\n        x, y = self.subset[index]\n        if self.transform:\n            x = self.transform(x)\n        return x, y\n\n    def __len__(self):\n        return len(self.subset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T14:01:33.115691Z","iopub.execute_input":"2025-03-02T14:01:33.115972Z","iopub.status.idle":"2025-03-02T14:01:40.442328Z","shell.execute_reply.started":"2025-03-02T14:01:33.115951Z","shell.execute_reply":"2025-03-02T14:01:40.441737Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data transforms\naugment_transform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.RandomRotation(10),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Load dataset and split\nfull_dataset = datasets.ImageFolder(root=TRAIN_DIR)\ntrain_size = int(0.8 * len(full_dataset))\nval_size = len(full_dataset) - train_size\ntrain_subset, val_subset = random_split(full_dataset, [train_size, val_size])\n\n# Create datasets\nno_augment_train = TransformedSubset(train_subset, test_transform)\naugment_train = TransformedSubset(train_subset, augment_transform)\nval_dataset = TransformedSubset(val_subset, test_transform)\n\n# Create dataloaders\nno_augment_loader = DataLoader(no_augment_train, BATCH_SIZE, shuffle=True)\naugment_loader = DataLoader(augment_train, BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, BATCH_SIZE, shuffle=False)\n\nnum_classes = len(full_dataset.classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T14:01:49.140699Z","iopub.execute_input":"2025-03-02T14:01:49.141007Z","iopub.status.idle":"2025-03-02T14:03:48.695006Z","shell.execute_reply.started":"2025-03-02T14:01:49.140982Z","shell.execute_reply":"2025-03-02T14:03:48.694387Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(full_dataset.classes))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T14:06:29.160636Z","iopub.execute_input":"2025-03-02T14:06:29.160933Z","iopub.status.idle":"2025-03-02T14:06:36.376853Z","shell.execute_reply.started":"2025-03-02T14:06:29.160911Z","shell.execute_reply":"2025-03-02T14:06:36.376240Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_model():\n    model = models.resnet34(pretrained=True)\n    num_ftrs = model.fc.in_features\n    model.fc = nn.Linear(num_ftrs, num_classes)\n    return model\n\ndef train_model(model,train_loader, val_loader, name):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n    # Tensor.cpu()\n    criterion = nn.CrossEntropyLoss()    #TENSOR\n    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n    scheduler = lr_scheduler.StepLR(optimizer, STEP_SIZE, GAMMA)\n\n    best_acc = 0.0\n    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n\n    for epoch in range(EPOCHS):\n        print(f'Epoch {epoch+1}/{EPOCHS}')\n        model.train()\n        running_loss = 0.0\n        running_corrects = 0\n\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n\n            outputs = model(inputs)\n            if isinstance(outputs, torch.nn.modules.container.ModuleDict):\n                outputs = outputs.logits  # Extract only the main output\n            loss = criterion(outputs, labels)\n\n            # outputs = model(inputs)       #INCEPTIONOUTPUT\n            # loss = criterion(outputs, labels) #EXPECTS TENSOR\n            loss.backward()\n            optimizer.step()\n            _, preds = torch.max(outputs, 1)\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        scheduler.step()\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n        history['train_loss'].append(epoch_loss)\n        history['train_acc'].append(epoch_acc)\n\n        print('hello')\n\n        # Validation\n        model.eval()\n        val_loss = 0.0\n        val_corrects = 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                _, preds = torch.max(outputs, 1)\n                val_loss += loss.item() * inputs.size(0)\n                val_corrects += torch.sum(preds == labels.data)\n\n        val_epoch_loss = val_loss / len(val_loader.dataset)\n        val_epoch_acc = val_corrects.double() / len(val_loader.dataset)\n        history['val_loss'].append(val_epoch_loss)\n        history['val_acc'].append(val_epoch_acc)\n\n        print(f'{name} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n        print(f'{name} Val Loss: {val_epoch_loss:.4f} Acc: {val_epoch_acc:.4f}\\n')\n        \n        wandb.log({f'{name} Train Loss': epoch_loss})\n        wandb.log({f'{name} Train Accuracy': epoch_acc.cpu().numpy()})\n        wandb.log({f'{name} Val Loss': val_epoch_loss})\n        wandb.log({f'{name} Val Accuracy': val_epoch_acc.cpu().numpy()})\n        SAVE_PATH = '/kaggle/working/best_model_inceptionv3.torch'\n        if val_epoch_acc > best_acc:\n            \n            best_acc = val_epoch_acc\n            best_model = copy.deepcopy(model.state_dict())\n            torch.save(best_model, SAVE_PATH)\n            wandb.save(SAVE_PATH)\n\n    model.load_state_dict(best_model)\n    wandb.finish()\n    return model, history\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T09:34:05.170859Z","iopub.execute_input":"2025-03-02T09:34:05.171193Z","iopub.status.idle":"2025-03-02T09:34:12.371384Z","shell.execute_reply.started":"2025-03-02T09:34:05.171165Z","shell.execute_reply":"2025-03-02T09:34:12.370719Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train without augmentation\nprint(\"Training without augmentation...\")\nmodel_no_aug, hist_no_aug = train_model(model, no_augment_loader, val_loader, \"No Aug\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T09:34:12.372393Z","iopub.execute_input":"2025-03-02T09:34:12.372626Z","iopub.status.idle":"2025-03-02T09:54:15.182154Z","shell.execute_reply.started":"2025-03-02T09:34:12.372594Z","shell.execute_reply":"2025-03-02T09:54:15.181121Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train with augmentation\nprint(\"\\nTraining with augmentation...\")\nmodel_aug, hist_aug = train_model(augment_loader, val_loader, \"Aug\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T07:32:38.445786Z","iopub.execute_input":"2025-03-01T07:32:38.446106Z","iopub.status.idle":"2025-03-01T09:07:57.547632Z","shell.execute_reply.started":"2025-03-01T07:32:38.446083Z","shell.execute_reply":"2025-03-01T09:07:57.546981Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot results\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(hist_no_aug['train_loss'], label='No Aug Train')\nplt.plot(hist_aug['train_loss'], label='Aug Train')\nplt.plot(hist_no_aug['val_loss'], '--', label='No Aug Val')\nplt.plot(hist_aug['val_loss'], '--', label='Aug Val')\nplt.title('Loss Comparison')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(hist_no_aug['train_acc'], label='No Aug Train')\nplt.plot(hist_aug['train_acc'], label='Aug Train')\nplt.plot(hist_no_aug['val_acc'], '--', label='No Aug Val')\nplt.plot(hist_aug['val_acc'], '--', label='Aug Val')\nplt.title('Accuracy Comparison')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T09:09:19.891338Z","iopub.execute_input":"2025-03-01T09:09:19.891689Z","iopub.status.idle":"2025-03-01T09:09:20.325734Z","shell.execute_reply.started":"2025-03-01T09:09:19.891663Z","shell.execute_reply":"2025-03-01T09:09:20.324493Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.subplot(1, 2, 2)\nplt.plot(hist_no_aug['train_acc'], label='No Aug Train')\nplt.plot(hist_aug['train_acc'], label='Aug Train')\nplt.plot(hist_no_aug['val_acc'], '--', label='No Aug Val')\nplt.plot(hist_aug['val_acc'], '--', label='Aug Val')\nplt.title('Accuracy Comparison')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T10:10:22.160698Z","iopub.execute_input":"2025-03-01T10:10:22.160986Z","iopub.status.idle":"2025-03-01T10:10:22.307785Z","shell.execute_reply.started":"2025-03-01T10:10:22.160964Z","shell.execute_reply":"2025-03-01T10:10:22.306665Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test evaluation\ntest_dataset = datasets.ImageFolder(TEST_DIR, test_transform)\ntest_loader = DataLoader(test_dataset, BATCH_SIZE, shuffle=False)\n\n\ndef evaluate(model, loader):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.eval()\n    all_preds = []\n    all_labels = []\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    \n    accuracy = 100 * correct / total\n    return all_labels, all_preds, accuracy\n\n# Evaluate best model\nlabels, preds, test_acc = evaluate(model_aug, test_loader)\nprint(\"Test Results:\")\nprint(classification_report(labels, preds, target_names=test_dataset.classes))\nprint(f\"Test Accuracy: {test_acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T10:02:10.748138Z","iopub.execute_input":"2025-03-01T10:02:10.748420Z","iopub.status.idle":"2025-03-01T10:02:59.054482Z","shell.execute_reply.started":"2025-03-01T10:02:10.748400Z","shell.execute_reply":"2025-03-01T10:02:59.053789Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compute the confusion matrix\ncm = confusion_matrix(labels, preds)\n\n# Plot the confusion matrix\nplt.figure(figsize=(20, 20))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=test_dataset.classes, \n            yticklabels=test_dataset.classes)\n\n# Labels and title\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\n\n# Show the plot\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T09:30:43.629128Z","iopub.execute_input":"2025-03-01T09:30:43.629510Z","iopub.status.idle":"2025-03-01T09:30:47.821580Z","shell.execute_reply.started":"2025-03-01T09:30:43.629481Z","shell.execute_reply":"2025-03-01T09:30:47.820644Z"}},"outputs":[],"execution_count":null}]}